{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesse\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data =pd.read_csv(\"test.csv\")\n",
    "\n",
    "airport_data = pd.read_csv(\"airports.csv\")\n",
    "weather_data = pd.read_csv(\"weather.csv\")\n",
    "sample_submission_data = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "d = {'DATE - YEAR':'year','DATE - MONTH':'month','DATE - DAY':'day'}\n",
    "\n",
    "train_data['date2'] = pd.to_datetime(train_data.rename(columns=d)[list(d.values())])\n",
    "test_data['date2'] = pd.to_datetime(train_data.rename(columns=d)[list(d.values())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>distance</th>\n",
       "      <th>date2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1030</td>\n",
       "      <td>1359</td>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2454</td>\n",
       "      <td>2013-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1630</td>\n",
       "      <td>1847</td>\n",
       "      <td>DL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>502</td>\n",
       "      <td>2013-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2055</td>\n",
       "      <td>2215</td>\n",
       "      <td>MQ</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>719</td>\n",
       "      <td>2013-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>855</td>\n",
       "      <td>1120</td>\n",
       "      <td>MQ</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>762</td>\n",
       "      <td>2013-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>852</td>\n",
       "      <td>1207</td>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SNA</td>\n",
       "      <td>2434</td>\n",
       "      <td>2013-09-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_delayed  year  month  day  sched_dep_time  sched_arr_time carrier  \\\n",
       "0   0           0  2013     12   15            1030            1359      UA   \n",
       "1   2           1  2013      4    2            1630            1847      DL   \n",
       "2   4           1  2013      5   13            2055            2215      MQ   \n",
       "3   7           0  2013      6    1             855            1120      MQ   \n",
       "4   8           0  2013      9   19             852            1207      UA   \n",
       "\n",
       "  origin dest  distance      date2  \n",
       "0    EWR  LAX      2454 2013-12-15  \n",
       "1    LGA  DTW       502 2013-04-02  \n",
       "2    EWR  ORD       719 2013-05-13  \n",
       "3    LGA  ATL       762 2013-06-01  \n",
       "4    EWR  SNA      2434 2013-09-19  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LAX', 'DTW', 'ORD', 'ATL', 'SNA', 'PHX', 'DEN', 'MIA', 'BOS',\n",
       "       'BWI', 'DFW', 'FLL', 'RDU', 'MYR', 'STL', 'CVG', 'GRR', 'PHL',\n",
       "       'TUL', 'BTV', 'SEA', 'CMH', 'BGR', 'MHT', 'CLT', 'LAS', 'MCO',\n",
       "       'AUS', 'SAT', 'OAK', 'DCA', 'MSY', 'CHS', 'SJC', 'RIC', 'OMA',\n",
       "       'TPA', 'SJU', 'JAX', 'PBI', 'MEM', 'LGB', 'SRQ', 'GSO', 'SFO',\n",
       "       'MKE', 'PDX', 'RSW', 'MDW', 'XNA', 'BUF', 'ACK', 'CLE', 'SAV',\n",
       "       'ROC', 'SAN', 'IND', 'TYS', 'BNA', 'DAY', 'MSP', 'PSE', 'MVY',\n",
       "       'PWM', 'CAK', 'ORF', 'MCI', 'SMF', 'IAH', 'IAD', 'PIT', 'HNL',\n",
       "       'HOU', 'SYR', 'BDL', 'STT', 'SLC', 'ALB', 'PVD', 'OKC', 'MSN',\n",
       "       'SDF', 'CAE', 'EGE', 'GSP', 'BQN', 'CRW', 'BUR', 'DSM', 'ILM',\n",
       "       'TVC', 'BHM', 'ABQ', 'HDN', 'AVL', 'BZN', 'SBN', 'CHO', 'MTJ',\n",
       "       'PSP', 'JAC', 'EYW', 'ANC', 'LEX', 'LGA'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data[\"carrier\"].unique() # too many categories\n",
    "#train_data[\"origin\"].unique()\n",
    "train_data[\"dest\"].unique() #too many categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES TO ADD TO TRAINING AND TEST:\n",
    "\n",
    "train_data = train_data.set_index('id')\n",
    "train_data.head()\n",
    "\n",
    "test_data = test_data.set_index('id')\n",
    "test_data.head()\n",
    "\n",
    "#%% Holiday to add as feature, on holidays we expect to see more flight delays\n",
    "import holidays\n",
    "us_holidays = holidays.US(years = 2013)\n",
    "train_data['holiday'] =train_data['date2'].isin(us_holidays)\n",
    "test_data['holiday'] =test_data['date2'].isin(us_holidays)\n",
    "\n",
    "#add daypart of sched_arr_time\n",
    "def dayPart(x):  \n",
    "    if x < 600: \n",
    "        return 'night'\n",
    "    elif x >= 600 and x < 1200:\n",
    "        return  'morning'\n",
    "    elif x >= 1200 and x < 1800:\n",
    "        return 'afternoon'\n",
    "    if x >= 1800 and x < 2400:\n",
    "        return 'evening'\n",
    "    \n",
    "train_data['sched_dep_time_daypart']= train_data['sched_dep_time'].apply(dayPart)\n",
    "test_data['sched_dep_time_daypart']= test_data['sched_dep_time'].apply(dayPart)\n",
    "train_data['sched_arr_time_daypart']= train_data['sched_arr_time'].apply(dayPart)\n",
    "test_data['sched_arr_time_daypart']= test_data['sched_arr_time'].apply(dayPart)\n",
    "\n",
    "def season(x):  \n",
    "    if x==1 or x==2 or x==3: \n",
    "        return 'winter'\n",
    "    if x==4 or x==5 or x==6: \n",
    "        return 'spring'\n",
    "    if x==7 or x==8 or x==9: \n",
    "        return 'summer'\n",
    "    if x==10 or x==11 or x==12: \n",
    "        return 'autumn'\n",
    "    \n",
    "train_data['sched_dep_time_season']= train_data['sched_dep_time'].apply(dayPart)\n",
    "test_data['sched_dep_time_season']= test_data['sched_dep_time'].apply(dayPart)\n",
    "\n",
    "def dayNumber(x):\n",
    "    import datetime\n",
    "        \n",
    "    return x.weekday()\n",
    "train_data['sched_dep_time_daynumber']= train_data['date2'].apply(dayNumber)\n",
    "test_data['sched_dep_time_daynumber']= test_data['date2'].apply(dayNumber)\n",
    "\n",
    "train_data['flightime'] = np.where(train_data['sched_arr_time'] - train_data['sched_dep_time'] < 0, \n",
    "          2360 - train_data['sched_dep_time'] + train_data['sched_arr_time'], \n",
    "          train_data['sched_arr_time'] - train_data['sched_dep_time'])\n",
    "\n",
    "test_data['flightime'] = np.where(test_data['sched_arr_time'] - test_data['sched_dep_time'] < 0, \n",
    "          2360 - test_data['sched_dep_time'] + test_data['sched_arr_time'], \n",
    "          test_data['sched_arr_time'] - test_data['sched_dep_time'])\n",
    "\n",
    "train_data.drop('date2',axis=1,inplace=True)\n",
    "test_data.drop('date2',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea's: Combine with airport dataset, calculate flight time, #flights on day (per location and total)\n",
    "#normelize/transform temperature to make low temperatures come forward stronger. Other normelization factors??\n",
    "#Binary encoding for carrier and des\n",
    "#Cluster algorithms for carrier and des.\n",
    "# Does it freeze?\n",
    "# numbers per day of week | weekday/weekend\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_delayed</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>distance</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sched_dep_time_daypart</th>\n",
       "      <th>sched_arr_time_daypart</th>\n",
       "      <th>sched_dep_time_season</th>\n",
       "      <th>sched_dep_time_daynumber</th>\n",
       "      <th>flightime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1030</td>\n",
       "      <td>1359</td>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2454</td>\n",
       "      <td>False</td>\n",
       "      <td>morning</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>morning</td>\n",
       "      <td>6</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1630</td>\n",
       "      <td>1847</td>\n",
       "      <td>DL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>502</td>\n",
       "      <td>False</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>evening</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2055</td>\n",
       "      <td>2215</td>\n",
       "      <td>MQ</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>719</td>\n",
       "      <td>False</td>\n",
       "      <td>evening</td>\n",
       "      <td>evening</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>855</td>\n",
       "      <td>1120</td>\n",
       "      <td>MQ</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>762</td>\n",
       "      <td>False</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>5</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>852</td>\n",
       "      <td>1207</td>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SNA</td>\n",
       "      <td>2434</td>\n",
       "      <td>False</td>\n",
       "      <td>morning</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>morning</td>\n",
       "      <td>3</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_delayed  year  month  day  sched_dep_time  sched_arr_time carrier  \\\n",
       "id                                                                         \n",
       "0            0  2013     12   15            1030            1359      UA   \n",
       "2            1  2013      4    2            1630            1847      DL   \n",
       "4            1  2013      5   13            2055            2215      MQ   \n",
       "7            0  2013      6    1             855            1120      MQ   \n",
       "8            0  2013      9   19             852            1207      UA   \n",
       "\n",
       "   origin dest  distance  holiday sched_dep_time_daypart  \\\n",
       "id                                                         \n",
       "0     EWR  LAX      2454    False                morning   \n",
       "2     LGA  DTW       502    False              afternoon   \n",
       "4     EWR  ORD       719    False                evening   \n",
       "7     LGA  ATL       762    False                morning   \n",
       "8     EWR  SNA      2434    False                morning   \n",
       "\n",
       "   sched_arr_time_daypart sched_dep_time_season  sched_dep_time_daynumber  \\\n",
       "id                                                                          \n",
       "0               afternoon               morning                         6   \n",
       "2                 evening             afternoon                         1   \n",
       "4                 evening               evening                         0   \n",
       "7                 morning               morning                         5   \n",
       "8               afternoon               morning                         3   \n",
       "\n",
       "    flightime  \n",
       "id             \n",
       "0         329  \n",
       "2         217  \n",
       "4         160  \n",
       "7         265  \n",
       "8         355  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faa</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>alt</th>\n",
       "      <th>tz</th>\n",
       "      <th>dst</th>\n",
       "      <th>tzone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04G</td>\n",
       "      <td>Lansdowne Airport</td>\n",
       "      <td>41.130472</td>\n",
       "      <td>-80.619583</td>\n",
       "      <td>1044</td>\n",
       "      <td>-5</td>\n",
       "      <td>A</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06A</td>\n",
       "      <td>Moton Field Municipal Airport</td>\n",
       "      <td>32.460572</td>\n",
       "      <td>-85.680028</td>\n",
       "      <td>264</td>\n",
       "      <td>-6</td>\n",
       "      <td>A</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06C</td>\n",
       "      <td>Schaumburg Regional</td>\n",
       "      <td>41.989341</td>\n",
       "      <td>-88.101243</td>\n",
       "      <td>801</td>\n",
       "      <td>-6</td>\n",
       "      <td>A</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06N</td>\n",
       "      <td>Randall Airport</td>\n",
       "      <td>41.431912</td>\n",
       "      <td>-74.391561</td>\n",
       "      <td>523</td>\n",
       "      <td>-5</td>\n",
       "      <td>A</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09J</td>\n",
       "      <td>Jekyll Island Airport</td>\n",
       "      <td>31.074472</td>\n",
       "      <td>-81.427778</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>A</td>\n",
       "      <td>America/New_York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   faa                           name        lat        lon   alt  tz dst  \\\n",
       "0  04G              Lansdowne Airport  41.130472 -80.619583  1044  -5   A   \n",
       "1  06A  Moton Field Municipal Airport  32.460572 -85.680028   264  -6   A   \n",
       "2  06C            Schaumburg Regional  41.989341 -88.101243   801  -6   A   \n",
       "3  06N                Randall Airport  41.431912 -74.391561   523  -5   A   \n",
       "4  09J          Jekyll Island Airport  31.074472 -81.427778    11  -5   A   \n",
       "\n",
       "              tzone  \n",
       "0  America/New_York  \n",
       "1   America/Chicago  \n",
       "2   America/Chicago  \n",
       "3  America/New_York  \n",
       "4  America/New_York  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD FEATURES TO WEATHERDATA\n",
    "\n",
    "# When it snows, there's more chance of a delay. Relative humidity is a possible estimator for this as discussed in this source:\n",
    "# http://www.sciencebits.com/SnowAboveFreezing\n",
    "import math \n",
    "\n",
    "def fahrenheitToCelcius(tf):\n",
    "    return (tf - 32) / 1.8\n",
    "\n",
    "def relativeHumidity(tc):\n",
    "    return 9.5 * math.exp((-17.27*tc)/(tc+238.3)) * (10.5-tc)\n",
    "    \n",
    "weather_data['tempcelcius'] = fahrenheitToCelcius(weather_data['temp'])\n",
    "weather_data['relative_humidity']  = weather_data['tempcelcius'].apply(relativeHumidity)\n",
    "\n",
    "weather_data.head()\n",
    "\n",
    "def freeze(x):  \n",
    "    if x < 0:\n",
    "        return 1\n",
    "    if x> 0: \n",
    "        return 0\n",
    "\n",
    "weather_data['freeze_at_departure']  = weather_data['tempcelcius'].apply(freeze)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>dewp</th>\n",
       "      <th>humid</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_gust</th>\n",
       "      <th>precip</th>\n",
       "      <th>pressure</th>\n",
       "      <th>visib</th>\n",
       "      <th>tempcelcius</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>freeze_at_departure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">EWR</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>39.02</td>\n",
       "      <td>26.06</td>\n",
       "      <td>59.37</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.35702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>47.478315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.02</td>\n",
       "      <td>26.96</td>\n",
       "      <td>61.63</td>\n",
       "      <td>250.0</td>\n",
       "      <td>8.05546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>47.478315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.02</td>\n",
       "      <td>28.04</td>\n",
       "      <td>64.43</td>\n",
       "      <td>240.0</td>\n",
       "      <td>11.50780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>47.478315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.92</td>\n",
       "      <td>28.04</td>\n",
       "      <td>62.21</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.65858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>42.371934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.02</td>\n",
       "      <td>28.04</td>\n",
       "      <td>64.43</td>\n",
       "      <td>260.0</td>\n",
       "      <td>12.65858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1011.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>47.478315</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             temp   dewp  humid  wind_dir  wind_speed  \\\n",
       "origin year month day hour                                              \n",
       "EWR    2013 1     1   1     39.02  26.06  59.37     270.0    10.35702   \n",
       "                      2     39.02  26.96  61.63     250.0     8.05546   \n",
       "                      3     39.02  28.04  64.43     240.0    11.50780   \n",
       "                      4     39.92  28.04  62.21     250.0    12.65858   \n",
       "                      5     39.02  28.04  64.43     260.0    12.65858   \n",
       "\n",
       "                            wind_gust  precip  pressure  visib  tempcelcius  \\\n",
       "origin year month day hour                                                    \n",
       "EWR    2013 1     1   1           NaN     0.0    1012.0   10.0          3.9   \n",
       "                      2           NaN     0.0    1012.3   10.0          3.9   \n",
       "                      3           NaN     0.0    1012.5   10.0          3.9   \n",
       "                      4           NaN     0.0    1012.2   10.0          4.4   \n",
       "                      5           NaN     0.0    1011.9   10.0          3.9   \n",
       "\n",
       "                            relative_humidity  freeze_at_departure  \n",
       "origin year month day hour                                          \n",
       "EWR    2013 1     1   1             47.478315                  0.0  \n",
       "                      2             47.478315                  0.0  \n",
       "                      3             47.478315                  0.0  \n",
       "                      4             42.371934                  0.0  \n",
       "                      5             47.478315                  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.drop('time_hour',axis=1,inplace=True)\n",
    "#weather_data.drop('hour',axis=1,inplace=True)\n",
    "\n",
    "weather_data_trans = weather_data.groupby(['origin','year','month','day']).mean()\n",
    "weather_data_trans2 = weather_data.groupby(['origin','year','month','day','hour']).mean()\n",
    "\n",
    "weather_data_trans2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data,weather_data_trans,  how='left', left_on=['origin','year','month','day'], right_index=True )\n",
    "test_data = pd.merge(test_data,weather_data_trans,  how='left', left_on=['origin','year','month','day'], right_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sched_dep_time_hour'] = train_data['sched_dep_time'].divide(100)\n",
    "train_data['sched_dep_time_hour'] = train_data['sched_dep_time_hour'].astype(np.int64)\n",
    "\n",
    "test_data['sched_dep_time_hour'] = test_data['sched_dep_time'].divide(100)\n",
    "test_data['sched_dep_time_hour'] = test_data['sched_dep_time_hour'].astype(np.int64)\n",
    "\n",
    "\n",
    "train_data = pd.merge(train_data,weather_data_trans2,  how='left', left_on=['origin','year','month','day','sched_dep_time_hour'], right_index=True )\n",
    "test_data = pd.merge(test_data,weather_data_trans2,  how='left', left_on=['origin','year','month','day','sched_dep_time_hour'], right_index=True )\n",
    "\n",
    "\n",
    "#Change NAN values for mean of month in each group\n",
    "def substituteNanNoncatMonth(data,columns):\n",
    "    for i in columns:\n",
    "        data[i] = data[[\"month\",i]].groupby(\"month\").transform(lambda x: x.fillna(x.mean()))\n",
    "    return data\n",
    "\n",
    "cols = ['sched_dep_time','flightime',\n",
    "       'sched_arr_time','distance',\n",
    "       'temp_x', 'dewp_x', 'humid_x', 'wind_dir_x', 'wind_speed_x', 'wind_gust_x',\n",
    "       'precip_x', 'pressure_x', 'visib_x','tempcelcius_x','relative_humidity_x',\n",
    "         'temp_y', 'dewp_y', 'humid_y', 'wind_dir_y', 'wind_speed_y', 'wind_gust_y',\n",
    "       'precip_y', 'pressure_y', 'visib_y','tempcelcius_y','relative_humidity_y','freeze_at_departure_x','freeze_at_departure_y']\n",
    "train_data = substituteNanNoncatMonth(train_data,cols)\n",
    "test_data = substituteNanNoncatMonth(test_data,cols)\n",
    "\n",
    "def substituteNanNoncatHour(data,columns):\n",
    "    for i in columns:\n",
    "        data[i] = data[['sched_dep_time_hour',i]].groupby('sched_dep_time_hour').transform(lambda x: x.fillna(x.mean()))\n",
    "    return data\n",
    "\n",
    "cols2 = ['temp_y', 'dewp_y', 'humid_y', 'wind_dir_y', 'wind_speed_y', 'wind_gust_y',\n",
    "       'precip_y', 'pressure_y', 'visib_y','tempcelcius_y','relative_humidity_y','freeze_at_departure_x','freeze_at_departure_y']\n",
    "train_data = substituteNanNoncatHour(train_data,cols2)\n",
    "test_data = substituteNanNoncatHour(test_data,cols2)\n",
    "\n",
    "train_data.drop('hour',axis=1,inplace=True)\n",
    "test_data.drop('hour',axis=1,inplace=True)\n",
    "train_data.drop('year',axis=1,inplace=True)\n",
    "test_data.drop('year',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [is_delayed, month, day, sched_dep_time, sched_arr_time, carrier, origin, dest, distance, holiday, sched_dep_time_daypart, sched_arr_time_daypart, sched_dep_time_season, sched_dep_time_daynumber, flightime, temp_x, dewp_x, humid_x, wind_dir_x, wind_speed_x, wind_gust_x, precip_x, pressure_x, visib_x, tempcelcius_x, relative_humidity_x, freeze_at_departure_x, sched_dep_time_hour, temp_y, dewp_y, humid_y, wind_dir_y, wind_speed_y, wind_gust_y, precip_y, pressure_y, visib_y, tempcelcius_y, relative_humidity_y, freeze_at_departure_y]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 40 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[train_data.isnull().any(axis=1)])\n",
    "x = pd.DataFrame([2359])\n",
    "x = x.divide(100)\n",
    "x.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_delayed                        1\n",
      "month                             3\n",
      "day                               6\n",
      "sched_dep_time                 1910\n",
      "sched_arr_time                 2228\n",
      "carrier                          B6\n",
      "origin                          JFK\n",
      "dest                            SLC\n",
      "distance                       1990\n",
      "holiday                       False\n",
      "sched_dep_time_daypart      evening\n",
      "sched_arr_time_daypart      evening\n",
      "sched_dep_time_season       evening\n",
      "sched_dep_time_daynumber          2\n",
      "flightime                       318\n",
      "temp_x                       39.515\n",
      "dewp_x                      30.5375\n",
      "humid_x                     70.3692\n",
      "wind_dir_x                    51.25\n",
      "wind_speed_x                24.1664\n",
      "wind_gust_x                 37.7335\n",
      "precip_x                          0\n",
      "pressure_x                   1012.5\n",
      "visib_x                     9.91667\n",
      "tempcelcius_x                 4.175\n",
      "relative_humidity_x         45.1171\n",
      "freeze_at_departure_x             0\n",
      "sched_dep_time_hour              19\n",
      "temp_y                        39.92\n",
      "dewp_y                        28.04\n",
      "humid_y                       62.21\n",
      "wind_dir_y                       20\n",
      "wind_speed_y                29.9203\n",
      "wind_gust_y                  36.825\n",
      "precip_y                          0\n",
      "pressure_y                   1012.5\n",
      "visib_y                          10\n",
      "tempcelcius_y                   4.4\n",
      "relative_humidity_y         42.3719\n",
      "freeze_at_departure_y             0\n",
      "Name: 1224, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[1224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t12.0\n",
      "  (0, 1)\t15.0\n",
      "  (0, 2)\t1030.0\n",
      "  (0, 3)\t329.0\n",
      "  (0, 4)\t1359.0\n",
      "  (0, 5)\t2454.0\n",
      "  (0, 6)\t34.527499999999996\n",
      "  (0, 7)\t28.602500000000003\n",
      "  (0, 8)\t80.52374999999999\n",
      "  (0, 9)\t243.33333333333334\n",
      "  (0, 10)\t12.658579999999999\n",
      "  (0, 11)\t23.59099\n",
      "  (0, 12)\t0.018333333333333333\n",
      "  (0, 13)\t1005.1263157894733\n",
      "  (0, 14)\t8.375\n",
      "  (0, 15)\t1.4041666666666666\n",
      "  (0, 16)\t79.73984615343194\n",
      "  (0, 17)\t33.98\n",
      "  (0, 18)\t30.02\n",
      "  (0, 19)\t86.39\n",
      "  (0, 20)\t270.0\n",
      "  (0, 21)\t13.80936\n",
      "  (0, 22)\t23.759510817008923\n",
      "  (0, 24)\t1019.7060884143726\n",
      "  (0, 25)\t10.0\n",
      "  :\t:\n",
      "  (168572, 9)\t210.43478260869566\n",
      "  (168572, 10)\t11.076257500000004\n",
      "  (168572, 11)\t21.673023333333333\n",
      "  (168572, 12)\t0.0029166666666666664\n",
      "  (168572, 13)\t1011.4411764705883\n",
      "  (168572, 14)\t9.666666666666666\n",
      "  (168572, 15)\t26.38333333333334\n",
      "  (168572, 16)\t-26.648680374822533\n",
      "  (168572, 17)\t75.92\n",
      "  (168572, 18)\t71.96\n",
      "  (168572, 19)\t87.55\n",
      "  (168572, 20)\t170.0\n",
      "  (168572, 21)\t12.65858\n",
      "  (168572, 22)\t22.01042889795897\n",
      "  (168572, 24)\t1011.7\n",
      "  (168572, 25)\t10.0\n",
      "  (168572, 26)\t24.4\n",
      "  (168572, 27)\t-26.55226792167479\n",
      "  (168572, 32)\t1.0\n",
      "  (168572, 33)\t1.0\n",
      "  (168572, 40)\t1.0\n",
      "  (168572, 72)\t1.0\n",
      "  (168572, 158)\t1.0\n",
      "  (168572, 162)\t1.0\n",
      "  (168572, 168)\t1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport category_encoders as ce\\n\\nencoder = ce.BinaryEncoder(cols=cat2)\\ndf_binary = encoder.fit(train_data[cat2])\\ntrain_data_cat_sparse2=enc.transform(train_data[cat2])\\ntest_data_cat_sparse2=enc.transform(test_data[cat2])\\n\\ntrain_data_sparse=hstack((train_data_sparse, train_data_cat_sparse2))\\ntest_data_sparse=hstack((test_data_sparse, test_data_cat_sparse2))\\n\\n\\n\\n\\n#If some categories don\\'t come forward in the test set, remove them\\ntrainlist = list(train_data)\\ntestlist = list(test_data)\\n\\nremovelist = [x for x in trainlist if x not in testlist]\\nremovelist = removelist +[x for x in testlist if x not in trainlist]\\n\\nremovelist.remove(\"is_delayed\")\\n\\ntry:\\n    train_data.drop(columns=removelist,axis=1)\\nexcept:\\n    print(\"do nothing\")\\ntry:\\n    test_data.drop(columns=removelist,axis=1)\\nexcept:\\n    print(\"do nothing\")\\n    '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat = [\"origin\",\"holiday\",'carrier','dest','sched_dep_time_daypart','sched_dep_time_season','sched_dep_time_daynumber']\n",
    "noncat = ['month','day', 'sched_dep_time','flightime',\n",
    "       'sched_arr_time','distance',\n",
    "       'temp_x', 'dewp_x', 'humid_x', 'wind_dir_x', 'wind_speed_x', 'wind_gust_x',\n",
    "       'precip_x', 'pressure_x', 'visib_x','tempcelcius_x','relative_humidity_x',\n",
    "         'temp_y', 'dewp_y', 'humid_y', 'wind_dir_y', 'wind_speed_y', 'wind_gust_y',\n",
    "       'precip_y', 'pressure_y', 'visib_y','tempcelcius_y','relative_humidity_y', 'freeze_at_departure_x','freeze_at_departure_y']\n",
    "label = ['is_delayed']\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(pd.concat([train_data[cat],test_data[cat]]))\n",
    "train_data_cat_sparse=enc.transform(train_data[cat])\n",
    "test_data_cat_sparse=enc.transform(test_data[cat])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "train_data_sparse=hstack((train_data[noncat], train_data_cat_sparse))\n",
    "test_data_sparse=hstack((test_data[noncat], test_data_cat_sparse))\n",
    "\n",
    "train_label = train_data['is_delayed'] \n",
    "\n",
    "print(train_data_sparse.tocsr())\n",
    "\"\"\"\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.BinaryEncoder(cols=cat2)\n",
    "df_binary = encoder.fit(train_data[cat2])\n",
    "train_data_cat_sparse2=enc.transform(train_data[cat2])\n",
    "test_data_cat_sparse2=enc.transform(test_data[cat2])\n",
    "\n",
    "train_data_sparse=hstack((train_data_sparse, train_data_cat_sparse2))\n",
    "test_data_sparse=hstack((test_data_sparse, test_data_cat_sparse2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#If some categories don't come forward in the test set, remove them\n",
    "trainlist = list(train_data)\n",
    "testlist = list(test_data)\n",
    "\n",
    "removelist = [x for x in trainlist if x not in testlist]\n",
    "removelist = removelist +[x for x in testlist if x not in trainlist]\n",
    "\n",
    "removelist.remove(\"is_delayed\")\n",
    "\n",
    "try:\n",
    "    train_data.drop(columns=removelist,axis=1)\n",
    "except:\n",
    "    print(\"do nothing\")\n",
    "try:\n",
    "    test_data.drop(columns=removelist,axis=1)\n",
    "except:\n",
    "    print(\"do nothing\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nscalevariables = ['sched_dep_time','sched_arr_time','distance','temp','dewp','humid','wind_dir','wind_speed','wind_gust','precip','pressure','visib']\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\ntrain_data = train_data.fillna(0)\\ntest_data = test_data.fillna(0)\\n\\n#We use the standard minmaxscaler as normelization factor\\nfor col in scalevariables:\\n    scaler = MinMaxScaler()\\n\\n    train_data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(train_data[col])),columns=[col])\\n    test_data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(test_data[col])),columns=[col])\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scalevariables = ['sched_dep_time','sched_arr_time','distance','temp','dewp','humid','wind_dir','wind_speed','wind_gust','precip','pressure','visib']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_data = train_data.fillna(0)\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "#We use the standard minmaxscaler as normelization factor\n",
    "for col in scalevariables:\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    train_data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(train_data[col])),columns=[col])\n",
    "    test_data[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(test_data[col])),columns=[col])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n#Decision Tree\\nfrom sklearn import tree\\nfrom sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    train_data.drop(\\'is_delayed\\',axis=1),train_data[\"is_delayed\"], test_size=0.4, random_state=0)\\n\\nclf = tree.DecisionTreeClassifier(min_samples_leaf=100,max_depth = 15)\\n\\nclf = clf.fit(X_train, y_train)\\ny_predict = clf.predict(X_test)\\n\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import roc_auc_score\\n\\nAUC = roc_auc_score(y_test, predictions)\\nprint(\"AUC = \" + str(AUC))\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data.drop('is_delayed',axis=1),train_data[\"is_delayed\"], test_size=0.4, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_leaf=100,max_depth = 15)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "AUC = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC = \" + str(AUC))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to DMatrices for optimized xgboost performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data_sparse,train_label, test_size=0.3, random_state=0)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "dtest = xgb.DMatrix(X_test,label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed: 155.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([1113.67024287, 1395.98677031,  808.14971066,  476.9962105 ,\n",
      "       1376.0057056 ,  463.88114206, 1287.70429476,  856.42309197,\n",
      "        455.55644377,  434.48569576]), 'std_fit_time': array([ 6.55250698,  1.57904979,  3.34411473,  4.16953679, 11.40357136,\n",
      "        1.81381846,  7.97637969,  3.7121089 ,  2.83670963,  1.28914487]), 'mean_score_time': array([26.1798776 , 30.71114723, 37.30920625, 11.88498878, 34.13819742,\n",
      "        8.43349179, 12.51541018, 22.29850332,  6.67864148,  6.96582659]), 'std_score_time': array([1.06344548, 0.78652864, 8.76183977, 0.32843658, 2.22638231,\n",
      "       0.24494347, 0.56521787, 2.37924983, 0.04125416, 1.33723087]), 'param_subsample': masked_array(data=[1.0, 0.8, 0.8, 0.6, 1.0, 0.8, 1.0, 0.8, 0.8, 0.8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_lambda': masked_array(data=[5, 3, 1, 3, 1, 3, 3, 3, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_alpha': masked_array(data=[5, 3, 5, 5, 5, 3, 3, 0, 5, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[7, 3, 10, 5, 3, 1, 5, 7, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[16, 17, 13, 8, 18, 6, 14, 16, 9, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[5, 5, 2, 2, 1.5, 1, 5, 2, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 0.8, 0.6, 0.6, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 1.0, 'reg_lambda': 5, 'reg_alpha': 5, 'min_child_weight': 7, 'max_depth': 16, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'reg_lambda': 3, 'reg_alpha': 3, 'min_child_weight': 3, 'max_depth': 17, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 5, 'min_child_weight': 10, 'max_depth': 13, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'reg_lambda': 3, 'reg_alpha': 5, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'reg_lambda': 1, 'reg_alpha': 5, 'min_child_weight': 3, 'max_depth': 18, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'reg_lambda': 3, 'reg_alpha': 3, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'reg_lambda': 3, 'reg_alpha': 3, 'min_child_weight': 5, 'max_depth': 14, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'reg_lambda': 3, 'reg_alpha': 0, 'min_child_weight': 7, 'max_depth': 16, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 5, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'reg_lambda': 1, 'reg_alpha': 3, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 0.8}], 'split0_test_score': array([0.78668091, 0.7893297 , 0.78857134, 0.77558575, 0.79331496,\n",
      "       0.76723463, 0.78801634, 0.79132707, 0.77921887, 0.78269483]), 'split1_test_score': array([0.79030176, 0.79321643, 0.79206524, 0.77947894, 0.79694619,\n",
      "       0.76950197, 0.79149544, 0.7950063 , 0.78261207, 0.78633824]), 'split2_test_score': array([0.78833139, 0.7899465 , 0.78953012, 0.77623363, 0.79398323,\n",
      "       0.76816665, 0.78936326, 0.79291201, 0.78091814, 0.78387493]), 'mean_test_score': array([0.78843801, 0.79083087, 0.79005556, 0.77709944, 0.79474812,\n",
      "       0.76830108, 0.789625  , 0.79308178, 0.78091635, 0.78430266]), 'std_test_score': array([0.00148013, 0.00170554, 0.00147398, 0.00170322, 0.00157803,\n",
      "       0.00093051, 0.00143235, 0.00150684, 0.00138528, 0.00151786]), 'rank_test_score': array([ 6,  3,  4,  9,  1, 10,  5,  2,  8,  7]), 'split0_train_score': array([0.85084205, 0.86788585, 0.87036849, 0.8172448 , 0.91932576,\n",
      "       0.79990887, 0.86485449, 0.95271483, 0.82378881, 0.83993247]), 'split1_train_score': array([0.84981838, 0.8659675 , 0.86959138, 0.81667964, 0.91654599,\n",
      "       0.79784435, 0.8636539 , 0.95266113, 0.82257879, 0.83841147]), 'split2_train_score': array([0.85120508, 0.8672947 , 0.8704211 , 0.81709393, 0.91937918,\n",
      "       0.7997488 , 0.86518511, 0.95370356, 0.82318199, 0.83922271]), 'mean_train_score': array([0.85062183, 0.86704935, 0.87012699, 0.81700612, 0.91841697,\n",
      "       0.79916734, 0.8645645 , 0.9530265 , 0.82318319, 0.83918888]), 'std_train_score': array([0.00058714, 0.00080215, 0.00037934, 0.00023893, 0.00132317,\n",
      "       0.00093777, 0.00065789, 0.00047925, 0.00049399, 0.00062141])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
      "       max_delta_step=0, max_depth=18, min_child_weight=3, missing=None,\n",
      "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=5, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1.0)\n",
      "\n",
      " Best normalized gini score for 3-fold search with 10 parameter combinations:\n",
      "0.58949624740947\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'reg_lambda': 1, 'reg_alpha': 5, 'min_child_weight': 3, 'max_depth': 18, 'gamma': 1.5, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "\n",
    "#source:https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "\n",
    "train_data_sparse_csr = train_data_sparse.tocsr()\n",
    "test_data_sparse_csr = test_data_sparse.tocsr()\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': [1,3, 5,7, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        #'reg_alpha':[0,3,5],\n",
    "        'reg_lambda':[1,3]\n",
    "        }\n",
    "\n",
    "folds = 3\n",
    "param_comb = 15\n",
    "\n",
    "model = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "#add early_stopping_rounds here?\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=3, cv=skf.split(train_data_sparse_csr,train_label), verbose=3 )\n",
    "\n",
    "random_search.fit(train_data_sparse_csr,train_label)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-05.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best XGBoost model with CV to leave as baseline - Overall AUC test/train data: 0.7869682439073855\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_data_sparse_csr = train_data_sparse.tocsr()\n",
    "test_data_sparse_csr = test_data_sparse.tocsr()\n",
    "\n",
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=1.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=18, min_child_weight=3, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=5, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    "## Or only use the train and validation set, so no cross validation:\n",
    "model.fit(train_data_sparse_csr,train_label, eval_metric='auc')\n",
    "\n",
    "# make predictions for test data\n",
    "#Set prediction of test set for submission\n",
    "pred_prob = model.predict_proba(test_data_sparse)\n",
    "\n",
    "#predictions = [round(value) for value in y_pred_prob[:,1]]\n",
    "predictions= [value for value in pred_prob[:,1]]\n",
    "\n",
    "#print('Overall AUC test/train data:', roc_auc_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "train_data_sparse_csr = train_data_sparse.tocsr()\n",
    "test_data_sparse_csr = test_data_sparse.tocsr()\n",
    "\n",
    "params = {\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3,6,9,12,15],\n",
    "        'max_features':[None,10,15],\n",
    "        'n_estimators':[100,125,150]\n",
    "        }\n",
    "\n",
    "folds = 3\n",
    "param_comb = 10\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "#add early_stopping_rounds here?\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=3, cv=skf.split(train_data_sparse_csr,train_label), verbose=3 )\n",
    "\n",
    "random_search.fit(train_data_sparse_csr,train_label)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('grad-boost-grid-search-results-01.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do nothing\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#If we don't want to work with sparse matrices:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "train_data2 = pd.get_dummies(train_data, columns=[\"year\",\"month\",\"day\",\"carrier\",\"origin\",\"dest\"], prefix=[\"year\",\"month\",\"day\",\"carrier\", \"origin\",\"dest\"])\n",
    "test_data2 = pd.get_dummies(test_data, columns=[\"year\",\"month\",\"day\",\"carrier\",\"origin\",\"dest\"], prefix=[\"year\",\"month\",\"day\",\"carrier\", \"origin\",\"dest\"])\n",
    "\n",
    "trainlist = list(train_data2)\n",
    "testlist = list(test_data2)\n",
    "\n",
    "removelist1 = [x for x in trainlist if x not in testlist]\n",
    "removelist2 = [x for x in testlist if x not in trainlist]\n",
    "\n",
    "removelist1.remove(\"is_delayed\")\n",
    "if removelist2 == None & removelist1 != None:\n",
    "    finalremovelist = removelist1\n",
    "elif removelist2 != None & removelist1 ==None:\n",
    "    finalremovelist = removelist2\n",
    "else: finalremovelistremovelist1.add(removelist2)\n",
    "\n",
    "try:\n",
    "    train_data2 = train_data2.drop(columns=finalremovelist,axis=1)\n",
    "except:\n",
    "    print(\"do nothing\")\n",
    "\n",
    "try:\n",
    "    test_data2 = test_data2.drop(columns=finalremovelist,axis=1) \n",
    "except:\n",
    "    print(\"do nothing\")\n",
    "    \n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC test/train data: 0.7861772949679726\n"
     ]
    }
   ],
   "source": [
    "#Best XGBoost model with CV to leave as baseline - Overall AUC test/train data: 0.7869682439073855\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data2.drop('is_delayed',axis=1),train_data2[\"is_delayed\"], test_size=0.4, random_state=0)\n",
    "\n",
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0.5, learning_rate=0.02,\n",
    "       max_delta_step=0, max_depth=15, min_child_weight=5, missing=None,\n",
    "       n_estimators=600, n_jobs=1, nthread=1, objective='binary:logistic',\n",
    "       random_state=0, reg_alpha=3, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1.0)\n",
    "\n",
    "## Or only use the train and validation set, so no cross validation:\n",
    "model.fit(X_train, y_train, eval_metric='auc')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "predictions = [value for value in y_pred_prob[:,1]]\n",
    "\n",
    "print('Overall AUC test/train data:', roc_auc_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sched_dep_time  sched_arr_time  distance  holiday   temp_x   dewp_x  \\\n",
      "id                                                                            \n",
      "1            47.478315            1430       944    False   821.28   443.64   \n",
      "3           -19.007343            1745       937    False  1266.06  1015.32   \n",
      "5           131.212063            2145       425    False   620.22   290.28   \n",
      "6           -16.767415            1857       746    False  1304.76   796.98   \n",
      "11          -26.944272            2115      2153    False  1852.68  1708.50   \n",
      "13          -26.066040            1518       937    False  1961.94  1612.02   \n",
      "15           36.639550            1103       828    False   973.20   640.20   \n",
      "17          -26.988207            2256      1990    False  2061.84  1710.48   \n",
      "18          -27.011672            1139       200    False  1900.02  1639.38   \n",
      "19           99.750000            1135       764    False   747.30   440.04   \n",
      "20           -9.059831            1842       762    False  1228.44  1163.82   \n",
      "25            8.162247            1425      1605    False  1053.84   542.64   \n",
      "26           59.856381            1631       746    False   835.32   377.94   \n",
      "30          -26.115920            2249       872    False  1776.54  1545.96   \n",
      "32          -13.848056            1754      2586    False  1405.56  1239.42   \n",
      "34          -20.880806            1501       544    False  1457.40   987.24   \n",
      "36           67.327455            1556       950    False   872.04   683.22   \n",
      "40          119.388804            1314       502    False   698.34   369.84   \n",
      "41          -26.997439            1300       764    False  1885.98  1646.22   \n",
      "42          -26.727044            1853      2153    False  1743.60  1365.60   \n",
      "43          -19.901607            2018       214    False  1495.02  1020.54   \n",
      "45          -26.861265            1915      1391    False  1830.18  1731.90   \n",
      "46          -27.011672            1642      1020    False  1757.28  1250.94   \n",
      "47           36.639550            1235       488    False   974.64   737.40   \n",
      "49          -13.848056            2253      2422    False  1405.56  1239.42   \n",
      "50          -17.833993            2323       529    False  1661.34  1550.10   \n",
      "52          -27.011672            1844       273    False  1833.96  1745.58   \n",
      "55          -26.653070            1544       733    False  2000.46  1688.34   \n",
      "56           82.487679             830       544    False   936.30   273.90   \n",
      "57          -25.490167            2156      1023    False  2167.32  1684.20   \n",
      "...                ...             ...       ...      ...      ...      ...   \n",
      "336719      -25.174330            1601      1969    False  1594.38  1489.80   \n",
      "336720       73.974050            1111      1005    False   871.14   471.90   \n",
      "336721       54.026946            1030       762    False   919.92   777.00   \n",
      "336722      -26.411674            1615      2133    False  1586.82  1419.42   \n",
      "336723       14.837841            1405      2586    False  1050.24   846.12   \n",
      "336726       27.162924            1438      1074    False   970.14   633.36   \n",
      "336727      195.884831            2130      2402    False   500.16   202.26   \n",
      "336730      -25.511227            1510      1372    False  1544.88  1239.78   \n",
      "336731      -20.880806            1635       427    False  1479.90  1439.76   \n",
      "336732      -17.833993            1735      1085    False  1343.82   954.66   \n",
      "336734       18.891676            2101      2133    False  1055.28   780.96   \n",
      "336735      131.212063            1854       266    False   673.50   222.60   \n",
      "336737      -17.833993            1418      1076    False  1357.14   897.06   \n",
      "336743      -26.552268            2021      2227    False  1630.38   987.42   \n",
      "336744        8.162247             725       212    False  1365.78   711.84   \n",
      "336745      -24.714178             835      1020    False  1834.32  1394.04   \n",
      "336749      -26.861265            2215       746    False  1782.70  1673.08   \n",
      "336750      -26.385212            1927      1035    False  1991.82  1538.04   \n",
      "336751       59.856381            1214      2153    False   900.70   528.46   \n",
      "336756       54.026946            1940      1065    False   844.14   810.12   \n",
      "336758      -26.956532            1635       213    False  1882.74  1606.98   \n",
      "336761      -20.880806            1000       944    False  1565.40  1197.30   \n",
      "336763      -15.373863            1033       254    False  1468.38   998.22   \n",
      "336764        8.162247            2230      2248    False  1023.78   828.66   \n",
      "336766        5.426099            1403      1605    False  1102.44   993.18   \n",
      "336767      -26.373377            1133      2227    False  1771.86  1387.38   \n",
      "336770       22.511161            1805      1389    False  1126.20  1033.86   \n",
      "336771       73.974050            1628       301    False   686.82   246.00   \n",
      "336772      -20.880806            1420       748    False  1338.24   886.80   \n",
      "336774       73.974050            1053       660    False   926.40   541.92   \n",
      "\n",
      "        humid_x  wind_dir_x  wind_speed_x  wind_gust_x    ...     dest_SNA  \\\n",
      "id                                                        ...                \n",
      "1       1379.24      7040.0     289.99656    153.05374    ...            0   \n",
      "3       1641.04      2500.0      96.66552      0.00000    ...            0   \n",
      "5       1360.34      5240.0     139.24438      0.00000    ...            0   \n",
      "6       1173.41      6640.0     397.01910    348.68634    ...            0   \n",
      "11      1984.49      4720.0     222.10054      0.00000    ...            0   \n",
      "13      1539.82      5520.0     266.98096    112.77644    ...            0   \n",
      "15      1395.47      7720.0     311.86138    144.99828    ...            0   \n",
      "17      1529.47      5640.0     329.12308    157.65686    ...            0   \n",
      "18      1710.26      5200.0     281.94110    174.91856    ...            0   \n",
      "19      1437.36      7110.0     300.35358    231.30678    ...            0   \n",
      "20      2194.20      2730.0     164.56154      0.00000    ...            0   \n",
      "25      1027.29      7610.0     394.71754    529.35880    ...            0   \n",
      "26      1137.88      6850.0     261.22706    144.99828    ...            0   \n",
      "30      1738.07      3720.0     189.87870    109.32410    ...            0   \n",
      "32      1899.05      3280.0     136.94282      0.00000    ...            0   \n",
      "34      1212.19      5510.0     215.19586     17.26170    ...            0   \n",
      "36      1795.58      8440.0     424.63782    520.15256    ...            0   \n",
      "40      1422.88      7760.0     449.95498    429.24094    ...            0   \n",
      "41      1763.08      5050.0     253.17160     56.38822    ...            0   \n",
      "42      1420.94      3920.0     208.29118      0.00000    ...            0   \n",
      "43      1195.81      5880.0     163.41076      0.00000    ...            0   \n",
      "45      2106.91      4260.0     217.49742      0.00000    ...            0   \n",
      "46      1162.75      6230.0     265.83018     92.06240    ...            0   \n",
      "47      1636.69      1200.0     508.64476    738.80076    ...            0   \n",
      "49      1899.05      3280.0     136.94282      0.00000    ...            0   \n",
      "50      2099.54      4080.0     243.96536    189.87870    ...            0   \n",
      "52      2139.64      4700.0     324.51996    105.87176    ...            0   \n",
      "55      1599.09      5170.0     256.62394    146.14906    ...            0   \n",
      "56       781.50      7210.0     392.41598    513.24788    ...            0   \n",
      "57      1290.87      5550.0     178.37090     52.93588    ...            0   \n",
      "...         ...         ...           ...          ...    ...          ...   \n",
      "336719  2109.14      4570.0     219.79898      0.00000    ...            0   \n",
      "336720  1231.80      6310.0     262.37784     18.41248    ...            0   \n",
      "336721  1924.17      4470.0     319.91684    132.33970    ...            0   \n",
      "336722  1921.02      3320.0     242.81458    197.93416    ...            0   \n",
      "336723  1738.92      2310.0     103.57020      0.00000    ...            0   \n",
      "336726  1388.12      6490.0     279.63954     43.72964    ...            0   \n",
      "336727  1441.56      7260.0     265.83018    169.16466    ...            0   \n",
      "336730  1569.62      1060.0     157.65686      0.00000    ...            0   \n",
      "336731  2280.87      2020.0     318.76606    191.02948    ...            0   \n",
      "336732  1338.14      2170.0     210.59274     37.97574    ...            0   \n",
      "336734  1564.24      5440.0     180.67246     18.41248    ...            0   \n",
      "336735  1091.18      6530.0     379.75740    403.92378    ...            0   \n",
      "336737  1178.85      1510.0     189.87870     21.86482    ...            0   \n",
      "336743   933.83      7580.0     300.35358    316.46450    ...            0   \n",
      "336744   940.83      5290.0     276.18720    283.09188    ...            0   \n",
      "336745  1282.58      5680.0     237.06068     42.57886    ...            0   \n",
      "336749  1985.62      2610.0      84.00694      0.00000    ...            0   \n",
      "336750  1306.71      5870.0     242.81458     21.86482    ...            0   \n",
      "336751  1228.92      4940.0     232.45756    150.75218    ...            0   \n",
      "336756  2291.70      4090.0     255.47316      0.00000    ...            0   \n",
      "336758  1659.76      5340.0     268.13174     49.48354    ...            0   \n",
      "336761  1466.47      7220.0     369.40038    306.10748    ...            0   \n",
      "336763  1178.54      3890.0     271.58408     20.71404    ...            0   \n",
      "336764  1769.11      4010.0     186.42636      0.00000    ...            0   \n",
      "336766  2039.68      2830.0     141.54594     37.97574    ...            0   \n",
      "336767  1438.77      4620.0     132.33970     85.15772    ...            0   \n",
      "336770  2104.40      5080.0     252.02082     19.56326    ...            0   \n",
      "336771  1102.31      7550.0     347.53556    218.64820    ...            0   \n",
      "336772  1229.15      2040.0     159.95842     95.51474    ...            0   \n",
      "336774  1259.50      4890.0     205.98962      0.00000    ...            0   \n",
      "\n",
      "        dest_SRQ  dest_STL  dest_STT  dest_SYR  dest_TPA  dest_TUL  dest_TVC  \\\n",
      "id                                                                             \n",
      "1              0         0         0         0         0         0         0   \n",
      "3              0         0         0         0         0         0         0   \n",
      "5              0         0         0         0         0         0         0   \n",
      "6              0         0         0         0         0         0         0   \n",
      "11             0         0         0         0         0         0         0   \n",
      "13             0         0         0         0         0         0         0   \n",
      "15             0         0         0         0         0         0         0   \n",
      "17             0         0         0         0         0         0         0   \n",
      "18             0         0         0         0         0         0         0   \n",
      "19             0         0         0         0         0         0         0   \n",
      "20             0         0         0         0         0         0         0   \n",
      "25             0         0         0         0         0         0         0   \n",
      "26             0         0         0         0         0         0         0   \n",
      "30             0         1         0         0         0         0         0   \n",
      "32             0         0         0         0         0         0         0   \n",
      "34             0         0         0         0         0         0         0   \n",
      "36             0         0         0         0         0         0         0   \n",
      "40             0         0         0         0         0         0         0   \n",
      "41             0         0         0         0         0         0         0   \n",
      "42             0         0         0         0         0         0         0   \n",
      "43             0         0         0         0         0         0         0   \n",
      "45             0         0         0         0         0         0         0   \n",
      "46             0         0         0         0         0         0         0   \n",
      "47             0         0         0         0         0         0         0   \n",
      "49             0         0         0         0         0         0         0   \n",
      "50             0         0         0         0         0         0         0   \n",
      "52             0         0         0         0         0         0         0   \n",
      "55             0         0         0         0         0         0         0   \n",
      "56             0         0         0         0         0         0         0   \n",
      "57             0         0         0         0         0         0         0   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "336719         0         0         0         0         0         0         0   \n",
      "336720         0         0         0         0         1         0         0   \n",
      "336721         0         0         0         0         0         0         0   \n",
      "336722         0         0         0         0         0         0         0   \n",
      "336723         0         0         0         0         0         0         0   \n",
      "336726         0         0         0         0         0         0         0   \n",
      "336727         0         0         0         0         0         0         0   \n",
      "336730         0         0         0         0         0         0         0   \n",
      "336731         0         0         0         0         0         0         0   \n",
      "336732         0         0         0         0         0         0         0   \n",
      "336734         0         0         0         0         0         0         0   \n",
      "336735         0         0         0         0         0         0         0   \n",
      "336737         0         0         0         0         0         0         0   \n",
      "336743         0         0         0         0         0         0         0   \n",
      "336744         0         0         0         0         0         0         0   \n",
      "336745         0         0         0         0         0         0         0   \n",
      "336749         0         0         0         0         0         0         0   \n",
      "336750         0         0         0         0         0         0         0   \n",
      "336751         0         0         0         0         0         0         0   \n",
      "336756         0         0         0         0         0         0         0   \n",
      "336758         0         0         0         0         0         0         0   \n",
      "336761         0         0         0         0         0         0         0   \n",
      "336763         0         0         0         0         0         0         0   \n",
      "336764         0         0         0         0         0         0         0   \n",
      "336766         0         0         0         0         0         0         0   \n",
      "336767         0         0         0         0         0         0         0   \n",
      "336770         0         0         0         0         0         0         0   \n",
      "336771         0         0         0         0         0         0         0   \n",
      "336772         0         0         0         0         0         0         0   \n",
      "336774         0         0         0         0         0         0         0   \n",
      "\n",
      "        dest_TYS  dest_XNA  \n",
      "id                          \n",
      "1              0         0  \n",
      "3              0         0  \n",
      "5              0         0  \n",
      "6              0         0  \n",
      "11             0         0  \n",
      "13             0         0  \n",
      "15             0         0  \n",
      "17             0         0  \n",
      "18             0         0  \n",
      "19             0         0  \n",
      "20             0         0  \n",
      "25             0         0  \n",
      "26             0         0  \n",
      "30             0         0  \n",
      "32             0         0  \n",
      "34             0         0  \n",
      "36             0         0  \n",
      "40             0         0  \n",
      "41             0         0  \n",
      "42             0         0  \n",
      "43             0         0  \n",
      "45             0         0  \n",
      "46             0         0  \n",
      "47             0         0  \n",
      "49             0         0  \n",
      "50             0         0  \n",
      "52             0         0  \n",
      "55             0         0  \n",
      "56             0         0  \n",
      "57             0         0  \n",
      "...          ...       ...  \n",
      "336719         0         0  \n",
      "336720         0         0  \n",
      "336721         0         0  \n",
      "336722         0         0  \n",
      "336723         0         0  \n",
      "336726         0         0  \n",
      "336727         0         0  \n",
      "336730         0         0  \n",
      "336731         0         0  \n",
      "336732         0         0  \n",
      "336734         0         0  \n",
      "336735         0         0  \n",
      "336737         0         0  \n",
      "336743         0         0  \n",
      "336744         0         0  \n",
      "336745         0         0  \n",
      "336749         0         0  \n",
      "336750         0         0  \n",
      "336751         0         0  \n",
      "336756         0         0  \n",
      "336758         0         0  \n",
      "336761         0         0  \n",
      "336763         0         0  \n",
      "336764         0         0  \n",
      "336766         0         0  \n",
      "336767         0         0  \n",
      "336770         0         0  \n",
      "336771         0         0  \n",
      "336772         0         0  \n",
      "336774         0         0  \n",
      "\n",
      "[168203 rows x 192 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "cat_features_index = [0,1,2,3,4,5,6]\n",
    "\n",
    "def auc(m, train, test): \n",
    "    return (metrics.roc_auc_score(y_train,m.predict_proba(train)[:,1]),\n",
    "                            metrics.roc_auc_score(y_test,m.predict_proba(test)[:,1]))\n",
    "\n",
    "#params = {'depth': [4, 7, 10],\n",
    "#          'learning_rate' : [0.03, 0.1, 0.15],\n",
    "#         'l2_leaf_reg': [1,4,9],\n",
    "#         'iterations': [300]}\n",
    "#cb = cb.CatBoostClassifier()\n",
    "#cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv = 3)\n",
    "#cb_model.fit(train, y_train)\n",
    "\n",
    "# Sem categoricas\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 100, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "clf.fit(train,y_train)\n",
    "auc(clf, train, test)\n",
    "\n",
    "# Com categoricas\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=31, \\\n",
    "                            depth=10, iterations= 100, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "clf.fit(train,y_train, cat_features= cat_features_index)\n",
    "auc(clf, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, X, y):\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        compute = cross_val_score(model, X, y, cv=10)\n",
    "        mean = compute.mean()\n",
    "        std = compute.std()\n",
    "        return mean, std\n",
    "\n",
    "def display_classifier_results(X,y):\n",
    "\n",
    "    models = []\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    models += [XGBClassifier()]\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    models += [KNeighborsClassifier()]\n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "    models += [GaussianNB(), MultinomialNB(), BernoulliNB()]\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier#, VotingClassifier\n",
    "    models += [RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier()]\n",
    "\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "    models += [LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "    from sklearn.svm import SVC, LinearSVC\n",
    "    models += [SVC(),LinearSVC()]\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    models += [SGDClassifier()]\n",
    "\n",
    "    from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "    models += [NearestCentroid()]\n",
    "\n",
    "    output = {}\n",
    "\n",
    "    for m in models:\n",
    "        try:\n",
    "            model_name = type(m).__name__\n",
    "            from time import time\n",
    "            start = time()\n",
    "            scores = get_results(m,X,y)\n",
    "            finish = time() - start\n",
    "            time_finished = \"%d minutes %2d seconds\" % (int(finish / 60), finish % 60) \n",
    "            row = {\"Mean Accuracy\" : scores[0], \"(+/-)\" : scores[1], \"Processing Time\": time_finished}\n",
    "            output[model_name] = row\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from IPython.display import display\n",
    "\n",
    "    result = DataFrame(data=output).T\n",
    "    result = result[[\"Mean Accuracy\", \"(+/-)\", \"Processing Time\"]]\n",
    "    display(result.sort_values(\"Mean Accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model if worth it\n",
    "import pickle\n",
    "\n",
    "# save model to file\n",
    "train.to_pickle(\"./train_pickle.pkl\")\n",
    "test.to_pickle(\"./test_pickle.pkl\")\n",
    " \n",
    "# load model from file\n",
    "train = read_pickle(\"./train_pickle.pkl\")\n",
    "test =  read_pickle(\"./test_pickle.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submission and save to file\n",
    "\n",
    "#Set prediction of test set for submission\n",
    "pred_prob = model.predict_proba(test_data_sparse)\n",
    "\n",
    "#predictions = [round(value) for value in y_pred_prob[:,1]]\n",
    "pred= [value for value in pred_prob[:,1]]\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test_data.index\n",
    "submission[\"is_delayed\"] = pred\n",
    "submission.to_csv(\"submission #10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-44c831f2ddfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"is_delayed\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission #9.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Make submission and save to file\n",
    "\n",
    "y_pred_prob = model.predict_proba(test_data_sparse)\n",
    "\n",
    "predictions = [value for value in y_pred_prob[:,1]]\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test_data2.index\n",
    "submission[\"is_delayed\"] = predictions\n",
    "submission.to_csv(\"submission #8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168203\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
